{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials, partial\n",
    "from hyperopt.early_stop import no_progress_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperopt_objective(X_train, y_train, iterations=50, early_stop=5):\n",
    "    data_xgb = xgb.DMatrix(X_train,y_train)\n",
    "\n",
    "    def opt_objective(params):\n",
    "        params_xgb = {\"eta\":params[\"eta\"]\n",
    "                    ,\"colsample_bytree\":params[\"colsample_bytree\"]\n",
    "                    # ,\"colsample_bynode\":params[\"colsample_bynode\"]\n",
    "                    # ,\"alpha\":params[\"alpha\"]\n",
    "                    ,\"gamma\":params[\"gamma\"]\n",
    "                    ,\"lambda\":params[\"lambda\"]\n",
    "                    ,\"min_child_weight\":params[\"min_child_weight\"]\n",
    "                    ,\"max_depth\":int(params[\"max_depth\"])\n",
    "                    # ,\"subsample\":params[\"subsample\"]\n",
    "                    # ,\"rate_drop\":params[\"rate_drop\"]\n",
    "\n",
    "                    ,\"booster\":\"gbtree\"\n",
    "                    ,\"objective\":'binary:logistic'\n",
    "                    ,\"nthread\":-1\n",
    "                    ,\"verbosity\":0}\n",
    "        result = xgb.cv(params_xgb\n",
    "                        ,data_xgb \n",
    "                        ,seed=seed\n",
    "                        ,nfold=5\n",
    "                        ,metrics=(\"logloss\") \n",
    "                        ,num_boost_round=int(params[\"num_boost_round\"]))\n",
    "        return result.iloc[-1,2]\n",
    "\n",
    "    params_grid = {'eta': hp.quniform('eta', 0.01, 0.11, 0.02)\n",
    "                    ,'num_boost_round': hp.quniform('num_boost_round', 100, 1001, 100)\n",
    "                    ,'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1.0, 0.1)\n",
    "                    # ,'colsample_bynode': hp.quniform('colsample_bynode', 0.1, 1.0, 0.1)\n",
    "                    ,'max_depth': hp.quniform('max_depth', 4, 5, 2)\n",
    "                    ,'min_child_weight': hp.quniform('min_child_weight', 5, 11, 2)\n",
    "                    # ,'alpha': hp.quniform('alpha', 0, 2, 0.05)\n",
    "                    ,'gamma': hp.quniform('gamma', 0, 0.5, 0.05)\n",
    "                    ,'lambda': hp.quniform('lambda', 0, 2, 0.05)\n",
    "                    # ,'subsample': hp.quniform('subsample', 0.4, 1.0, 0.1)\n",
    "                    # ,\"rate_drop\":hp.quniform(\"rate_drop\",0.0, 1.01, 0.05)\n",
    "                    }\n",
    "\n",
    "\n",
    "    def param_hyperopt(num_iter, early_stop):\n",
    "        trials = Trials()\n",
    "        early_stop_fn = no_progress_loss(early_stop) # stop if no progress after 50 iterations\n",
    "        params_best = fmin(opt_objective\n",
    "                        , space = params_grid\n",
    "                        , algo = tpe.suggest\n",
    "                        , max_evals = num_iter\n",
    "                        , verbose=True\n",
    "                        , trials = trials\n",
    "                        , early_stop_fn = early_stop_fn\n",
    "                        )\n",
    "        \n",
    "        params_best['num_boost_round'] = int(params_best['num_boost_round'])\n",
    "        params_best['max_depth'] = int(params_best['max_depth'])\n",
    "\n",
    "        print(\"\\n\",\"\\n\",\"best params: \", params_best,\n",
    "                \"\\n\")\n",
    "        return params_best, trials\n",
    "\n",
    "    def hyperopt_validation(params, dtrain, dval, y_val):\n",
    "        model = xgb.train(params, data_xgb)\n",
    "\n",
    "        y_pred = model.predict(dval)\n",
    "        y_pred = np.where(y_pred>0.5,1,0)\n",
    "\n",
    "        f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "        return f1\n",
    "\n",
    "\n",
    "    params_best, trials = param_hyperopt(num_iter=iterations, early_stop=early_stop) # number of iterations and number of iterations without progress to stop\n",
    "    train_f1 = hyperopt_validation(params_best, data_xgb, data_xgb, y_train)\n",
    "    # validation_f1 = hyperopt_validation(params_best, data_xgb, data_xgb_validation, y_val)\n",
    "    # print(f'Train F1: {train_f1}, Validation F1: {validation_f1}')\n",
    "    print(f'Train F1: {train_f1}')\n",
    "\n",
    "    model = xgb.train(params_best, data_xgb, num_boost_round=int(params_best[\"num_boost_round\"]))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_search = \"Baysien\"\n",
    "if hyperparameter_search == \"Baysien\":\n",
    "    params_chosen = {'colsample_bytree': 0.8, 'eta': 0.02, 'gamma': 0.35000000000000003, 'lambda': 0.15000000000000002, 'max_depth': 4, 'min_child_weight': 6.0, 'num_boost_round': 100}\n",
    "    search=False\n",
    "    if search:\n",
    "        model = hyperopt_objective(X_train, y_train, iterations=100, early_stop=30)\n",
    "    else:\n",
    "        model = xgb.train(params_chosen\n",
    "                            ,xgb.DMatrix(X_train,y_train)\n",
    "                            ,num_boost_round=params_chosen[\"num_boost_round\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
